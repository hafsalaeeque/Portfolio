{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Bringing data generated from my GCT Test.\n",
    "gct2011 = pd.read_csv('granger_results2011.csv')\n",
    "\n",
    "# These results are only with a max lag of 3\n",
    "gct_cvt = pd.read_csv('granger_results_cut.csv')\n",
    "gct_tvc = pd.read_csv('granger_results_cut_tvc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I went back and re-ran the GCT with a Max lag of 6.  These files or those results.\n",
    "gct_lag6_tvc = pd.read_csv('gct_lag6_tvc.csv')\n",
    "gct_lag6_cvt = pd.read_csv('gct_lag6_cvt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the 4 types of metrics reported by the Statsmodel Granger Causality Test\n",
    "- F Test\n",
    "- Chi2\n",
    "- LR\n",
    "- Params F Test\n",
    "\n",
    "Pretty much all of these measures show 3 things.\n",
    "- Measure of error reported in Chi2 or F-test\n",
    "- P-Value \n",
    "- DF, which i am uncertain of what it means but its just seems to be a count of the total observations\n",
    "\n",
    "Im pretty sure I am interested in the P-Value and either accepting or rejecting the null hypothesis\n",
    "- Specific Cased can be come back to in order to evaluate the Chi2 or F values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tvc -  Traps vs. Crash. This will show if crashes are the lagged result of speed traps \n",
    "    - H-Null = There is no time series relation of Speed Trap observations causing Crash observations\n",
    "cvt -  Crash vs. Traps. This will show if Traps are the lagged result of crashes.\n",
    "    - H-Null = There is no time series relation of Crash observations causing Speed Trap observations\n",
    "    \n",
    "A P-Value of < 0.05 is cause enough to reject the Null Hypothesis and that the observations could possibly support the Test hypothesis.\n",
    "\n",
    "Take all values where p-values that are less than 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ----------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crash vs. Trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Unnamed: 0', 'Location', 'lag1_Ftest', 'lag1_CHI2', 'lag1_LR',\n",
       "       'lag1_params_Ftest', 'lag2_Ftest', 'lag2_CHI2', 'lag2_LR',\n",
       "       'lag2_params_Ftest', 'lag3_Ftest', 'lag3_CHI2', 'lag3_LR',\n",
       "       'lag3_params_Ftest', 'lag4_Ftest', 'lag4_CHI2', 'lag4_LR',\n",
       "       'lag4_params_Ftest', 'lag5_Ftest', 'lag5_CHI2', 'lag5_LR',\n",
       "       'lag5_params_Ftest', 'lag6_Ftest', 'lag6_CHI2', 'lag6_LR',\n",
       "       'lag6_params_Ftest'], dtype=object)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#test_df = gct_cvt[['Locations',]]\n",
    "gct_lag6_cvt.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialized cvt_pvalues dataframe where i am going to take all of the pvalues from my dataframe of scores.  \n",
    "cvt_lag6_pvalues = pd.DataFrame(gct_lag6_cvt['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "''' \n",
    "For Simplicity and Sampling I am only going to look at the results from lags of 1,3 & 6 months.\n",
    "The way data was entered into this DF (when I did the test) The Error, p-value and DF are recorded in the same line\n",
    "I need to split that string an extract the values that I want which are only p-values for the time being. \n",
    "'''\n",
    "\n",
    "listo =[]\n",
    "for item in gct_lag6_cvt['lag1_Ftest']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listo.append(float(value))\n",
    "cvt_lag6_pvalues['lag1_Ftest'] = listo\n",
    "\n",
    "lista =[]\n",
    "for item in gct_lag6_cvt['lag1_CHI2']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    lista.append(float(value))\n",
    "cvt_lag6_pvalues['lag1_CHI2'] = lista\n",
    "\n",
    "listb =[]\n",
    "for item in gct_lag6_cvt['lag1_LR']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listb.append(float(value))\n",
    "cvt_lag6_pvalues['lag1_LR'] = listb\n",
    "\n",
    "listc =[]\n",
    "for item in gct_lag6_cvt['lag1_params_Ftest']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listc.append(float(value))\n",
    "cvt_lag6_pvalues['lag1_params_Ftest'] = listc\n",
    "\n",
    "listd =[]\n",
    "for item in gct_lag6_cvt['lag3_Ftest']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listd.append(float(value))\n",
    "cvt_lag6_pvalues['lag3_Ftest'] = listd\n",
    "\n",
    "liste =[]\n",
    "for item in gct_lag6_cvt['lag3_CHI2']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    liste.append(float(value))\n",
    "cvt_lag6_pvalues['lag3_CHI2'] = liste\n",
    "\n",
    "listf =[]\n",
    "for item in gct_lag6_cvt['lag3_LR']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listf.append(float(value))\n",
    "cvt_lag6_pvalues['lag3_LR'] = listf\n",
    "\n",
    "listg =[]\n",
    "for item in gct_lag6_cvt['lag3_params_Ftest']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listg.append(float(value))\n",
    "cvt_lag6_pvalues['lag3_params_Ftest'] = listg\n",
    "\n",
    "listh =[]\n",
    "for item in gct_lag6_cvt['lag6_Ftest']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listh.append(float(value))\n",
    "cvt_lag6_pvalues['lag6_Ftest'] = listh\n",
    "\n",
    "listi =[]\n",
    "for item in gct_lag6_cvt['lag6_CHI2']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listi.append(float(value))\n",
    "cvt_lag6_pvalues['lag6_CHI2'] = listi\n",
    "\n",
    "listj =[]\n",
    "for item in gct_lag6_cvt['lag6_LR']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listj.append(float(value))\n",
    "cvt_lag6_pvalues['lag6_LR'] = listj\n",
    "\n",
    "listk =[]\n",
    "for item in gct_lag6_cvt['lag6_params_Ftest']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listk.append(float(value))\n",
    "cvt_lag6_pvalues['lag6_params_Ftest'] = listk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating individual dataframes base of of lag period values\n",
    "cvt_pvalues_lag1 = cvt_lag6_pvalues[['Location','lag1_Ftest','lag1_CHI2','lag1_LR','lag1_params_Ftest']]\n",
    "\n",
    "cvt_pvalues_lag3 = cvt_lag6_pvalues[['Location','lag3_Ftest','lag3_CHI2','lag3_LR','lag3_params_Ftest']]\n",
    "\n",
    "cvt_pvalues_lag6 = cvt_lag6_pvalues[['Location','lag6_Ftest','lag6_CHI2','lag6_LR','lag6_params_Ftest']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/samuelstack/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "/Users/samuelstack/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/Users/samuelstack/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Here is a method to take the Avarage P-Value across all of the metrics.  I was told later this probably not a great idea\n",
    "'''\n",
    "# cvt_pvalues_lag1['avg_p'] = (cvt_pvalues_lag1['lag1_Ftest']+cvt_pvalues_lag1['lag1_CHI2']+cvt_pvalues_lag1['lag1_LR']\n",
    "#                              +cvt_pvalues_lag1['lag1_params_Ftest'])/4\n",
    "\n",
    "# cvt_pvalues_lag2['avg_p'] = (cvt_pvalues_lag2['lag2_Ftest']+cvt_pvalues_lag2['lag2_CHI2']+cvt_pvalues_lag2['lag2_LR']\n",
    "#                              +cvt_pvalues_lag2['lag2_params_Ftest'])/4\n",
    "\n",
    "# cvt_pvalues_lag3['avg_p'] = (cvt_pvalues_lag3['lag3_Ftest']+cvt_pvalues_lag3['lag3_CHI2']+cvt_pvalues_lag3['lag3_LR']\n",
    "#                              +cvt_pvalues_lag3['lag3_params_Ftest'])/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trap vs. Crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tvc_lag6_pvalues = pd.DataFrame(gct_lag6_tvc['Location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Extracting P-Values \n",
    "listo =[]\n",
    "for item in gct_lag6_tvc['lag1_Ftest']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listo.append(float(value))\n",
    "tvc_lag6_pvalues['lag1_Ftest'] = listo\n",
    "\n",
    "lista =[]\n",
    "for item in gct_lag6_tvc['lag1_CHI2']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    lista.append(float(value))\n",
    "tvc_lag6_pvalues['lag1_CHI2'] = lista\n",
    "\n",
    "listb =[]\n",
    "for item in gct_lag6_tvc['lag1_LR']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listb.append(float(value))\n",
    "tvc_lag6_pvalues['lag1_LR'] = listb\n",
    "\n",
    "listc =[]\n",
    "for item in gct_lag6_tvc['lag1_params_Ftest']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listc.append(float(value))\n",
    "tvc_lag6_pvalues['lag1_params_Ftest'] = listc\n",
    "\n",
    "\n",
    "# Lag3\n",
    "\n",
    "listh =[]\n",
    "for item in gct_lag6_tvc['lag3_Ftest']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listh.append(float(value))\n",
    "tvc_lag6_pvalues['lag3_Ftest'] = listh\n",
    "\n",
    "listi =[]\n",
    "for item in gct_lag6_tvc['lag3_CHI2']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listi.append(float(value))\n",
    "tvc_lag6_pvalues['lag3_CHI2'] = listi\n",
    "\n",
    "listj =[]\n",
    "for item in gct_lag6_tvc['lag3_LR']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listj.append(float(value))\n",
    "tvc_lag6_pvalues['lag3_LR'] = listj\n",
    "\n",
    "listk =[]\n",
    "for item in gct_lag6_tvc['lag3_params_Ftest']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listk.append(float(value))\n",
    "tvc_lag6_pvalues['lag3_params_Ftest'] = listk\n",
    "\n",
    "#Lag 6\n",
    "\n",
    "listd =[]\n",
    "for item in gct_lag6_tvc['lag6_Ftest']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listd.append(float(value))\n",
    "tvc_lag6_pvalues['lag6_Ftest'] = listd\n",
    "\n",
    "liste =[]\n",
    "for item in gct_lag6_tvc['lag6_CHI2']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    liste.append(float(value))\n",
    "tvc_lag6_pvalues['lag6_CHI2'] = liste\n",
    "\n",
    "listf =[]\n",
    "for item in gct_lag6_tvc['lag6_LR']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listf.append(float(value))\n",
    "tvc_lag6_pvalues['lag6_LR'] = listf\n",
    "\n",
    "listg =[]\n",
    "for item in gct_lag6_tvc['lag6_params_Ftest']:\n",
    "    obj = item.split()\n",
    "    value = obj[1]\n",
    "    value = value.replace(',','')\n",
    "    listg.append(float(value))\n",
    "tvc_lag6_pvalues['lag6_params_Ftest'] = listg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TVC_pvalues_lagx are the values of the Trap vs Crash GCT associated with that degree of lag\n",
    "# tvc_lag6_pvalues are the pvalues taken from the GCT that executed UP TO 6 lags.\n",
    "\n",
    "tvc_pvalues_lag1 = tvc_lag6_pvalues[['Location','lag1_Ftest','lag1_CHI2','lag1_LR','lag1_params_Ftest']]\n",
    "\n",
    "tvc_pvalues_lag3 = tvc_lag6_pvalues[['Location','lag3_Ftest','lag3_CHI2','lag3_LR','lag3_params_Ftest']]\n",
    "\n",
    "tvc_pvalues_lag6 = tvc_lag6_pvalues[['Location','lag6_Ftest','lag6_CHI2','lag6_LR','lag6_params_Ftest']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Once again a bonehead move\n",
    "# tvc_pvalues_lag1['avg_p'] = (tvc_pvalues_lag1['lag1_Ftest']+tvc_pvalues_lag1['lag1_CHI2']+tvc_pvalues_lag1['lag1_LR']\n",
    "#                              +tvc_pvalues_lag1['lag1_params_Ftest'])/4\n",
    "\n",
    "# tvc_pvalues_lag2['avg_p'] = (tvc_pvalues_lag2['lag2_Ftest']+tvc_pvalues_lag2['lag2_CHI2']+tvc_pvalues_lag2['lag2_LR']\n",
    "#                              +tvc_pvalues_lag2['lag2_params_Ftest'])/4\n",
    "\n",
    "# tvc_pvalues_lag3['avg_p'] = (tvc_pvalues_lag3['lag3_Ftest']+tvc_pvalues_lag3['lag3_CHI2']+tvc_pvalues_lag3['lag3_LR']\n",
    "#                              +tvc_pvalues_lag3['lag3_params_Ftest'])/4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ladies and Gentlemen!  This is where I draw the Conclussion.\n",
    "My threshold is %95 confidence, so i am only interest in results where there is an average P-Value below 0.05 indicating that we fail to reject the Null Hypothesis.\n",
    "\n",
    "- TvC HNull = Crashes do not Granger Cause Traps to be placed and thus tickets to occur.\n",
    "\n",
    "- TvC H = Crashes do Granger Cause the placement of traps and thus tickets in a location.\n",
    "\n",
    "- CvT HNull = Traps do not granger cause Crashes and thus placement of traps encourages safe driving habbits.\n",
    "\n",
    "- CvT H = Traps Granger cause more wreckless driving in an area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Trap vs. Crash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the locations and lags with P-values less than 0.05.  \n",
    "\n",
    "con_tvc_lag1 = tvc_pvalues_lag1[['Location','lag1_LR' ]][(tvc_pvalues_lag1['lag1_LR'] < 0.05)]\n",
    "con_tvc_lag3 = tvc_pvalues_lag3[['Location','lag3_LR' ]][(tvc_pvalues_lag3['lag3_LR'] < 0.05)]\n",
    "con_tvc_lag6 = tvc_pvalues_lag6[['Location','lag6_LR' ]][(tvc_pvalues_lag6['lag6_LR'] < 0.05)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure out how to extract the location and p-values less than 5 and convert said values back to long/lat\n",
    "get the data for deaths and injuries from crashes and over lay them in tableau."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Crash vs. Trap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the locations and lags with P-values less than 0.05.  \n",
    "con_cvt_lag1 = cvt_pvalues_lag1[['Location','lag1_LR' ]][(cvt_pvalues_lag1['lag1_LR'] < 0.05)]\n",
    "con_cvt_lag3 = cvt_pvalues_lag3[['Location','lag3_LR' ]][(cvt_pvalues_lag3['lag3_LR'] < 0.05)]\n",
    "con_cvt_lag6 = cvt_pvalues_lag6[['Location','lag6_LR' ]][(cvt_pvalues_lag6['lag6_LR'] < 0.05)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping data for visual analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Renaming columns \n",
    "con_tvc_lag1.rename(columns ={'lag1_LR': 'P-Value'}, inplace = True)\n",
    "con_tvc_lag3.rename(columns ={'lag3_LR': 'P-Value'}, inplace = True)\n",
    "con_tvc_lag6.rename(columns ={'lag6_LR': 'P-Value'}, inplace = True)\n",
    "\n",
    "con_cvt_lag1.rename(columns ={'lag1_LR': 'P-Value'}, inplace = True)\n",
    "con_cvt_lag3.rename(columns ={'lag3_LR': 'P-Value'}, inplace = True)\n",
    "con_cvt_lag6.rename(columns ={'lag6_LR': 'P-Value'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creating a column called 'Lag Period'\n",
    "con_cvt_lag1['Lag Period'] = 1\n",
    "con_cvt_lag3['Lag Period'] = 2\n",
    "con_cvt_lag6['Lag Period'] = 6\n",
    "\n",
    "con_tvc_lag1['Lag Period'] = 1\n",
    "con_tvc_lag3['Lag Period'] = 3\n",
    "con_tvc_lag6['Lag Period'] = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Converting String Location to Longitude and Latitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Crash_vs_Trap = pd.concat([con_cvt_lag1,con_cvt_lag3,con_cvt_lag6])\n",
    "Trap_vs_Crash = pd.concat([con_tvc_lag1,con_tvc_lag3,con_tvc_lag6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Unique Location is currently a string, i am going to split it and convert Longitude and Latitude back to Floats.\n",
    "locale = Crash_vs_Trap['Location']\n",
    "\n",
    "lat = []\n",
    "lon = []\n",
    "\n",
    "for item in locale:\n",
    "    coord = item.split()\n",
    "    x = coord[0].replace(',','')\n",
    "    lat.append(float(x))\n",
    "    y = coord[1].replace(',','')\n",
    "    lon.append(float(y))\n",
    "    \n",
    "Crash_vs_Trap['Latitude'] = lat\n",
    "Crash_vs_Trap['Longitude'] = lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# saving incase my kernel dies\n",
    "Crash_vs_Trap.to_csv('crash_vs_trap.csv')\n",
    "Trap_vs_Crash.to_csv('trap_vs_crash.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "locale = Trap_vs_Crash['Location']\n",
    "\n",
    "lat = []\n",
    "lon = []\n",
    "\n",
    "for item in locale:\n",
    "    coord = item.split()\n",
    "    x = coord[0].replace(',','')\n",
    "    lat.append(float(x))\n",
    "    y = coord[1].replace(',','')\n",
    "    lon.append(float(y))\n",
    "    \n",
    "Trap_vs_Crash['Latitude'] = lat\n",
    "Trap_vs_Crash['Longitude'] = lon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
